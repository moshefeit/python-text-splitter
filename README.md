# python-text-splitter
*Python script to split a really big text file to multiple files by lines*

If you need to upload a dataset that is so big in size to GitHub, they won't allow you. So, why don't you just *split it* into multiple files and join them later in the cloud?

This script is built with **Python 2.7**, on **Windows** environment, on **.TXT** file. Other than that, haven't been tested yet.

You need only the **complete path** of the file, and this script will do the job.
This script works based on lines. And splitting is based on Github upload limit.

Say:

```
111111
222222
333333
444444
555555
```

* 111111 → written to file1
* 222222 → written to file2
* 333333 → written to file3
* and so on...

Just download or copy the code from `Main.py` and store it yourself. Open up command prompt:

1. `cd path/to/main.py`
2. `python main.py`


***ps:* Suggestions are welcome**
